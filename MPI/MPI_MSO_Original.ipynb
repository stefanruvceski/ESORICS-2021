{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "560de52d041bc622820064af0057252378a1e2e0d406082954e0fb64c745b95b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array,float64\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,RepeatVector,TimeDistributed\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.getcwd())\n",
    "\n",
    "df_train = load_dataset(path + '/data/2015_train.csv')\n",
    "df_test = load_dataset(path + '/data/2015_test.csv')\n",
    "\n",
    "train_set = get_df_values(df_train) \n",
    "test_set = get_df_values(df_test)\n",
    "\n",
    "X,y = split_sequences(sequences=train_set, n_steps_in = 20, n_steps_out = 10)\n",
    "\n",
    "model = compile_model(n_steps_in = 20,n_steps_out = 10,n_features_in = 51)\n",
    "print(model.summary())\n",
    "\n",
    "history = train_model(model=model,X=X,y=y,_validation_split = 0.3,_epoch=100,_batch_size=32,\n",
    "_modelCheckpoint_path=path + '/MPI/TempOriginal',_modelCheckpoint_monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name):\n",
    "    df = read_csv(name)\n",
    "    df.drop(['Timestamp','Status'],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_values(df):\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix,:]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(n_steps_in,n_steps_out,n_features_in):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features_in)))\n",
    "     \n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features_in)))\n",
    "    model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,X,y,_validation_split,_epoch,_batch_size,_modelCheckpoint_path,_modelCheckpoint_monitor):\n",
    "    return model.fit(X,y,validation_split=_validation_split, epochs = _epoch, batch_size = _batch_size, callbacks= [EarlyStopping(patience=3), ModelCheckpoint(_modelCheckpoint_path, monitor=_modelCheckpoint_monitor,save_best_only=True)], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.6985213, 1.7024342, 1.702454, 1.7024537, 1.7024537, 1.7024537, 1.7024537, 1.7024537, 1.7024537, 1.7024537]\n[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "row = 5000\n",
    "x_input = test_set[row-22:row-2]\n",
    "x_input = x_input.reshape((1, 20, 51))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "actual = test_set[row-2:row+8,3]\n",
    "predict = []\n",
    "for sec in yhat[0]:\n",
    "    predict.append(sec[3])\n",
    "\n",
    "print(predict)\n",
    "print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}